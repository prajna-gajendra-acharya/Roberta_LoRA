{
  "best_global_step": 22380,
  "best_metric": 0.9328125,
  "best_model_checkpoint": "/content/drive/MyDrive/DL_Project_2/results/Final_Results/checkpoint-22380",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 22380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013404825737265416,
      "grad_norm": 1.6989483833312988,
      "learning_rate": 1.0835567470956211e-06,
      "loss": 0.2365,
      "step": 100
    },
    {
      "epoch": 0.02680965147453083,
      "grad_norm": 3.485536813735962,
      "learning_rate": 2.2006255585344057e-06,
      "loss": 0.2588,
      "step": 200
    },
    {
      "epoch": 0.040214477211796246,
      "grad_norm": 7.480974197387695,
      "learning_rate": 3.3176943699731907e-06,
      "loss": 0.2754,
      "step": 300
    },
    {
      "epoch": 0.05361930294906166,
      "grad_norm": 5.618712425231934,
      "learning_rate": 4.434763181411975e-06,
      "loss": 0.2249,
      "step": 400
    },
    {
      "epoch": 0.06702412868632708,
      "grad_norm": 2.8641438484191895,
      "learning_rate": 5.55183199285076e-06,
      "loss": 0.2271,
      "step": 500
    },
    {
      "epoch": 0.08042895442359249,
      "grad_norm": 3.2393527030944824,
      "learning_rate": 6.668900804289545e-06,
      "loss": 0.2213,
      "step": 600
    },
    {
      "epoch": 0.0938337801608579,
      "grad_norm": 3.074885606765747,
      "learning_rate": 7.785969615728329e-06,
      "loss": 0.235,
      "step": 700
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 3.81085467338562,
      "learning_rate": 8.903038427167114e-06,
      "loss": 0.2492,
      "step": 800
    },
    {
      "epoch": 0.12064343163538874,
      "grad_norm": 10.949390411376953,
      "learning_rate": 1.0020107238605898e-05,
      "loss": 0.2365,
      "step": 900
    },
    {
      "epoch": 0.13404825737265416,
      "grad_norm": 5.598736763000488,
      "learning_rate": 1.1137176050044684e-05,
      "loss": 0.2361,
      "step": 1000
    },
    {
      "epoch": 0.14745308310991956,
      "grad_norm": 12.025008201599121,
      "learning_rate": 1.2254244861483467e-05,
      "loss": 0.2591,
      "step": 1100
    },
    {
      "epoch": 0.16085790884718498,
      "grad_norm": 6.5901780128479,
      "learning_rate": 1.3371313672922253e-05,
      "loss": 0.2554,
      "step": 1200
    },
    {
      "epoch": 0.1742627345844504,
      "grad_norm": 3.561748743057251,
      "learning_rate": 1.4488382484361038e-05,
      "loss": 0.2744,
      "step": 1300
    },
    {
      "epoch": 0.1876675603217158,
      "grad_norm": 10.607654571533203,
      "learning_rate": 1.5605451295799824e-05,
      "loss": 0.2427,
      "step": 1400
    },
    {
      "epoch": 0.20107238605898123,
      "grad_norm": 7.852214336395264,
      "learning_rate": 1.6722520107238606e-05,
      "loss": 0.254,
      "step": 1500
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 3.0835156440734863,
      "learning_rate": 1.783958891867739e-05,
      "loss": 0.2834,
      "step": 1600
    },
    {
      "epoch": 0.22788203753351208,
      "grad_norm": 0.8331916928291321,
      "learning_rate": 1.8956657730116176e-05,
      "loss": 0.2365,
      "step": 1700
    },
    {
      "epoch": 0.24128686327077747,
      "grad_norm": 4.768577575683594,
      "learning_rate": 2.0073726541554962e-05,
      "loss": 0.2331,
      "step": 1800
    },
    {
      "epoch": 0.2546916890080429,
      "grad_norm": 6.115420341491699,
      "learning_rate": 2.1190795352993744e-05,
      "loss": 0.2317,
      "step": 1900
    },
    {
      "epoch": 0.2680965147453083,
      "grad_norm": 0.24915894865989685,
      "learning_rate": 2.230786416443253e-05,
      "loss": 0.2753,
      "step": 2000
    },
    {
      "epoch": 0.28150134048257375,
      "grad_norm": 0.9396265149116516,
      "learning_rate": 2.3424932975871315e-05,
      "loss": 0.2448,
      "step": 2100
    },
    {
      "epoch": 0.2949061662198391,
      "grad_norm": 4.925902843475342,
      "learning_rate": 2.4542001787310097e-05,
      "loss": 0.2435,
      "step": 2200
    },
    {
      "epoch": 0.30831099195710454,
      "grad_norm": 4.33419942855835,
      "learning_rate": 2.5659070598748886e-05,
      "loss": 0.2165,
      "step": 2300
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 2.1820425987243652,
      "learning_rate": 2.676496872207328e-05,
      "loss": 0.2373,
      "step": 2400
    },
    {
      "epoch": 0.3351206434316354,
      "grad_norm": 8.796798706054688,
      "learning_rate": 2.7882037533512067e-05,
      "loss": 0.2305,
      "step": 2500
    },
    {
      "epoch": 0.3485254691689008,
      "grad_norm": 10.433491706848145,
      "learning_rate": 2.899910634495085e-05,
      "loss": 0.2328,
      "step": 2600
    },
    {
      "epoch": 0.36193029490616624,
      "grad_norm": 10.29844856262207,
      "learning_rate": 3.0116175156389638e-05,
      "loss": 0.2216,
      "step": 2700
    },
    {
      "epoch": 0.3753351206434316,
      "grad_norm": 3.535597801208496,
      "learning_rate": 3.123324396782842e-05,
      "loss": 0.2176,
      "step": 2800
    },
    {
      "epoch": 0.38873994638069703,
      "grad_norm": 4.570897102355957,
      "learning_rate": 3.235031277926721e-05,
      "loss": 0.2477,
      "step": 2900
    },
    {
      "epoch": 0.40214477211796246,
      "grad_norm": 1.731355905532837,
      "learning_rate": 3.346738159070599e-05,
      "loss": 0.213,
      "step": 3000
    },
    {
      "epoch": 0.4155495978552279,
      "grad_norm": 1.078394889831543,
      "learning_rate": 3.458445040214477e-05,
      "loss": 0.2398,
      "step": 3100
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 3.378371238708496,
      "learning_rate": 3.5701519213583554e-05,
      "loss": 0.2264,
      "step": 3200
    },
    {
      "epoch": 0.44235924932975873,
      "grad_norm": 0.7739254236221313,
      "learning_rate": 3.681858802502234e-05,
      "loss": 0.1999,
      "step": 3300
    },
    {
      "epoch": 0.45576407506702415,
      "grad_norm": 0.4309842884540558,
      "learning_rate": 3.7935656836461125e-05,
      "loss": 0.2082,
      "step": 3400
    },
    {
      "epoch": 0.4691689008042895,
      "grad_norm": 1.8324979543685913,
      "learning_rate": 3.9052725647899914e-05,
      "loss": 0.2513,
      "step": 3500
    },
    {
      "epoch": 0.48257372654155495,
      "grad_norm": 13.976000785827637,
      "learning_rate": 4.01697944593387e-05,
      "loss": 0.2375,
      "step": 3600
    },
    {
      "epoch": 0.4959785522788204,
      "grad_norm": 11.702929496765137,
      "learning_rate": 4.1286863270777485e-05,
      "loss": 0.192,
      "step": 3700
    },
    {
      "epoch": 0.5093833780160858,
      "grad_norm": 6.75333833694458,
      "learning_rate": 4.240393208221627e-05,
      "loss": 0.2008,
      "step": 3800
    },
    {
      "epoch": 0.5227882037533512,
      "grad_norm": 29.876859664916992,
      "learning_rate": 4.352100089365505e-05,
      "loss": 0.2313,
      "step": 3900
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 5.28196907043457,
      "learning_rate": 4.463806970509384e-05,
      "loss": 0.2502,
      "step": 4000
    },
    {
      "epoch": 0.5495978552278821,
      "grad_norm": 0.6353716254234314,
      "learning_rate": 4.575513851653262e-05,
      "loss": 0.2196,
      "step": 4100
    },
    {
      "epoch": 0.5630026809651475,
      "grad_norm": 8.85328197479248,
      "learning_rate": 4.687220732797141e-05,
      "loss": 0.2236,
      "step": 4200
    },
    {
      "epoch": 0.5764075067024129,
      "grad_norm": 5.7490153312683105,
      "learning_rate": 4.798927613941019e-05,
      "loss": 0.2229,
      "step": 4300
    },
    {
      "epoch": 0.5898123324396782,
      "grad_norm": Infinity,
      "learning_rate": 4.910634495084897e-05,
      "loss": 0.2226,
      "step": 4400
    },
    {
      "epoch": 0.6032171581769437,
      "grad_norm": 1.1470248699188232,
      "learning_rate": 4.999997255572855e-05,
      "loss": 0.2207,
      "step": 4500
    },
    {
      "epoch": 0.6166219839142091,
      "grad_norm": 7.286746025085449,
      "learning_rate": 4.99989234470642e-05,
      "loss": 0.2111,
      "step": 4600
    },
    {
      "epoch": 0.6300268096514745,
      "grad_norm": 7.912576198577881,
      "learning_rate": 4.999635395304943e-05,
      "loss": 0.2185,
      "step": 4700
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 6.426968574523926,
      "learning_rate": 4.999226422995579e-05,
      "loss": 0.2453,
      "step": 4800
    },
    {
      "epoch": 0.6568364611260054,
      "grad_norm": 11.38541316986084,
      "learning_rate": 4.998665452651221e-05,
      "loss": 0.2303,
      "step": 4900
    },
    {
      "epoch": 0.6702412868632708,
      "grad_norm": 6.812958717346191,
      "learning_rate": 4.9979525183889816e-05,
      "loss": 0.2141,
      "step": 5000
    },
    {
      "epoch": 0.6836461126005362,
      "grad_norm": 0.7502947449684143,
      "learning_rate": 4.9970876635681206e-05,
      "loss": 0.2074,
      "step": 5100
    },
    {
      "epoch": 0.6970509383378016,
      "grad_norm": 9.551376342773438,
      "learning_rate": 4.996070940787406e-05,
      "loss": 0.2166,
      "step": 5200
    },
    {
      "epoch": 0.710455764075067,
      "grad_norm": 5.619749546051025,
      "learning_rate": 4.9949024118819184e-05,
      "loss": 0.1725,
      "step": 5300
    },
    {
      "epoch": 0.7238605898123325,
      "grad_norm": 7.75204610824585,
      "learning_rate": 4.9935821479192865e-05,
      "loss": 0.171,
      "step": 5400
    },
    {
      "epoch": 0.7372654155495979,
      "grad_norm": 4.335638046264648,
      "learning_rate": 4.992110229195368e-05,
      "loss": 0.2016,
      "step": 5500
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 6.660914421081543,
      "learning_rate": 4.990486745229364e-05,
      "loss": 0.2345,
      "step": 5600
    },
    {
      "epoch": 0.7640750670241286,
      "grad_norm": 1.9511847496032715,
      "learning_rate": 4.988711794758376e-05,
      "loss": 0.2081,
      "step": 5700
    },
    {
      "epoch": 0.7774798927613941,
      "grad_norm": 9.595823287963867,
      "learning_rate": 4.9867854857314015e-05,
      "loss": 0.2162,
      "step": 5800
    },
    {
      "epoch": 0.7908847184986595,
      "grad_norm": 6.904327392578125,
      "learning_rate": 4.984707935302764e-05,
      "loss": 0.2282,
      "step": 5900
    },
    {
      "epoch": 0.8042895442359249,
      "grad_norm": 1.097462773323059,
      "learning_rate": 4.982479269824996e-05,
      "loss": 0.2011,
      "step": 6000
    },
    {
      "epoch": 0.8176943699731903,
      "grad_norm": 0.9140496253967285,
      "learning_rate": 4.980099624841147e-05,
      "loss": 0.1794,
      "step": 6100
    },
    {
      "epoch": 0.8310991957104558,
      "grad_norm": 0.33414381742477417,
      "learning_rate": 4.977569145076545e-05,
      "loss": 0.2194,
      "step": 6200
    },
    {
      "epoch": 0.8445040214477212,
      "grad_norm": 5.69442081451416,
      "learning_rate": 4.97488798442999e-05,
      "loss": 0.2116,
      "step": 6300
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 1.5267729759216309,
      "learning_rate": 4.972056305964401e-05,
      "loss": 0.1833,
      "step": 6400
    },
    {
      "epoch": 0.871313672922252,
      "grad_norm": 35.06755065917969,
      "learning_rate": 4.9691048457603716e-05,
      "loss": 0.2322,
      "step": 6500
    },
    {
      "epoch": 0.8847184986595175,
      "grad_norm": 3.65165376663208,
      "learning_rate": 4.9659741581664566e-05,
      "loss": 0.2219,
      "step": 6600
    },
    {
      "epoch": 0.8981233243967829,
      "grad_norm": 6.698000431060791,
      "learning_rate": 4.962693494874885e-05,
      "loss": 0.2196,
      "step": 6700
    },
    {
      "epoch": 0.9115281501340483,
      "grad_norm": 10.596277236938477,
      "learning_rate": 4.959263055409147e-05,
      "loss": 0.2433,
      "step": 6800
    },
    {
      "epoch": 0.9249329758713136,
      "grad_norm": 4.695500373840332,
      "learning_rate": 4.9556830484018216e-05,
      "loss": 0.203,
      "step": 6900
    },
    {
      "epoch": 0.938337801608579,
      "grad_norm": 6.076635360717773,
      "learning_rate": 4.9519536915818925e-05,
      "loss": 0.2362,
      "step": 7000
    },
    {
      "epoch": 0.9517426273458445,
      "grad_norm": 3.721658945083618,
      "learning_rate": 4.9480752117615076e-05,
      "loss": 0.2146,
      "step": 7100
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 1.4017407894134521,
      "learning_rate": 4.94404784482218e-05,
      "loss": 0.2199,
      "step": 7200
    },
    {
      "epoch": 0.9785522788203753,
      "grad_norm": 6.666066646575928,
      "learning_rate": 4.939871835700444e-05,
      "loss": 0.2077,
      "step": 7300
    },
    {
      "epoch": 0.9919571045576407,
      "grad_norm": 3.3125736713409424,
      "learning_rate": 4.93554743837296e-05,
      "loss": 0.2446,
      "step": 7400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.91875,
      "eval_f1": 0.9195137868585593,
      "eval_loss": 0.26531127095222473,
      "eval_precision": 0.9199812563224562,
      "eval_recall": 0.9210448216571784,
      "eval_runtime": 0.732,
      "eval_samples_per_second": 874.32,
      "eval_steps_per_second": 13.661,
      "step": 7460
    },
    {
      "epoch": 1.0053619302949062,
      "grad_norm": 10.897499084472656,
      "learning_rate": 4.9310749158410695e-05,
      "loss": 0.262,
      "step": 7500
    },
    {
      "epoch": 1.0187667560321716,
      "grad_norm": 3.4865188598632812,
      "learning_rate": 4.926501474830144e-05,
      "loss": 0.2484,
      "step": 7600
    },
    {
      "epoch": 1.032171581769437,
      "grad_norm": 8.35981559753418,
      "learning_rate": 4.9217350012131223e-05,
      "loss": 0.2143,
      "step": 7700
    },
    {
      "epoch": 1.0455764075067024,
      "grad_norm": 9.725339889526367,
      "learning_rate": 4.916821242436952e-05,
      "loss": 0.2345,
      "step": 7800
    },
    {
      "epoch": 1.0589812332439679,
      "grad_norm": 2.7087814807891846,
      "learning_rate": 4.9117604973467756e-05,
      "loss": 0.2033,
      "step": 7900
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 4.364835739135742,
      "learning_rate": 4.906553073727154e-05,
      "loss": 0.2384,
      "step": 8000
    },
    {
      "epoch": 1.0857908847184987,
      "grad_norm": 4.510557651519775,
      "learning_rate": 4.901199288283349e-05,
      "loss": 0.2068,
      "step": 8100
    },
    {
      "epoch": 1.0991957104557641,
      "grad_norm": 7.361072540283203,
      "learning_rate": 4.8956994666220615e-05,
      "loss": 0.2238,
      "step": 8200
    },
    {
      "epoch": 1.1126005361930296,
      "grad_norm": 1.6351211071014404,
      "learning_rate": 4.890053943231625e-05,
      "loss": 0.1998,
      "step": 8300
    },
    {
      "epoch": 1.126005361930295,
      "grad_norm": 3.8965847492218018,
      "learning_rate": 4.884263061461668e-05,
      "loss": 0.234,
      "step": 8400
    },
    {
      "epoch": 1.1394101876675604,
      "grad_norm": 19.319774627685547,
      "learning_rate": 4.878327173502229e-05,
      "loss": 0.2058,
      "step": 8500
    },
    {
      "epoch": 1.1528150134048256,
      "grad_norm": 9.298149108886719,
      "learning_rate": 4.872246640362337e-05,
      "loss": 0.2181,
      "step": 8600
    },
    {
      "epoch": 1.1662198391420913,
      "grad_norm": 1.0362467765808105,
      "learning_rate": 4.8660218318480574e-05,
      "loss": 0.2176,
      "step": 8700
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 8.58491325378418,
      "learning_rate": 4.85965312654e-05,
      "loss": 0.2191,
      "step": 8800
    },
    {
      "epoch": 1.193029490616622,
      "grad_norm": 6.4015984535217285,
      "learning_rate": 4.853140911770294e-05,
      "loss": 0.2346,
      "step": 8900
    },
    {
      "epoch": 1.2064343163538873,
      "grad_norm": 11.524066925048828,
      "learning_rate": 4.846485583599031e-05,
      "loss": 0.2197,
      "step": 9000
    },
    {
      "epoch": 1.2198391420911527,
      "grad_norm": 3.5578572750091553,
      "learning_rate": 4.83968754679018e-05,
      "loss": 0.219,
      "step": 9100
    },
    {
      "epoch": 1.2332439678284182,
      "grad_norm": 5.374725818634033,
      "learning_rate": 4.8327472147869684e-05,
      "loss": 0.2123,
      "step": 9200
    },
    {
      "epoch": 1.2466487935656836,
      "grad_norm": 5.553110122680664,
      "learning_rate": 4.8256650096867364e-05,
      "loss": 0.2535,
      "step": 9300
    },
    {
      "epoch": 1.260053619302949,
      "grad_norm": 3.9010701179504395,
      "learning_rate": 4.818441362215266e-05,
      "loss": 0.2015,
      "step": 9400
    },
    {
      "epoch": 1.2734584450402144,
      "grad_norm": 1.2335041761398315,
      "learning_rate": 4.811076711700588e-05,
      "loss": 0.1891,
      "step": 9500
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 5.864121913909912,
      "learning_rate": 4.8035715060462614e-05,
      "loss": 0.2042,
      "step": 9600
    },
    {
      "epoch": 1.3002680965147453,
      "grad_norm": 4.250343322753906,
      "learning_rate": 4.79600334671637e-05,
      "loss": 0.2137,
      "step": 9700
    },
    {
      "epoch": 1.3136729222520107,
      "grad_norm": 2.892094850540161,
      "learning_rate": 4.788219802666439e-05,
      "loss": 0.2049,
      "step": 9800
    },
    {
      "epoch": 1.3270777479892761,
      "grad_norm": 6.68065881729126,
      "learning_rate": 4.7802970935891055e-05,
      "loss": 0.207,
      "step": 9900
    },
    {
      "epoch": 1.3404825737265416,
      "grad_norm": 2.6467065811157227,
      "learning_rate": 4.7722357013279516e-05,
      "loss": 0.188,
      "step": 10000
    },
    {
      "epoch": 1.353887399463807,
      "grad_norm": 6.695239067077637,
      "learning_rate": 4.7640361161609975e-05,
      "loss": 0.1709,
      "step": 10100
    },
    {
      "epoch": 1.3672922252010724,
      "grad_norm": 0.8348463773727417,
      "learning_rate": 4.755698836770885e-05,
      "loss": 0.2233,
      "step": 10200
    },
    {
      "epoch": 1.3806970509383378,
      "grad_norm": 3.935314178466797,
      "learning_rate": 4.7472243702145455e-05,
      "loss": 0.2403,
      "step": 10300
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 1.2931849956512451,
      "learning_rate": 4.738613231892367e-05,
      "loss": 0.2092,
      "step": 10400
    },
    {
      "epoch": 1.4075067024128687,
      "grad_norm": 7.526734352111816,
      "learning_rate": 4.7298659455168424e-05,
      "loss": 0.2094,
      "step": 10500
    },
    {
      "epoch": 1.420911528150134,
      "grad_norm": 4.611133575439453,
      "learning_rate": 4.7209830430807244e-05,
      "loss": 0.2185,
      "step": 10600
    },
    {
      "epoch": 1.4343163538873995,
      "grad_norm": 5.489882946014404,
      "learning_rate": 4.711965064824665e-05,
      "loss": 0.2228,
      "step": 10700
    },
    {
      "epoch": 1.447721179624665,
      "grad_norm": 0.30868276953697205,
      "learning_rate": 4.702812559204364e-05,
      "loss": 0.2322,
      "step": 10800
    },
    {
      "epoch": 1.4611260053619302,
      "grad_norm": 3.9551661014556885,
      "learning_rate": 4.693526082857209e-05,
      "loss": 0.2054,
      "step": 10900
    },
    {
      "epoch": 1.4745308310991958,
      "grad_norm": 7.453378200531006,
      "learning_rate": 4.684106200568426e-05,
      "loss": 0.2081,
      "step": 11000
    },
    {
      "epoch": 1.487935656836461,
      "grad_norm": 10.888154983520508,
      "learning_rate": 4.674553485236726e-05,
      "loss": 0.2073,
      "step": 11100
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 4.300311088562012,
      "learning_rate": 4.664868517839464e-05,
      "loss": 0.1923,
      "step": 11200
    },
    {
      "epoch": 1.5147453083109919,
      "grad_norm": 0.9087520241737366,
      "learning_rate": 4.655051887397307e-05,
      "loss": 0.2094,
      "step": 11300
    },
    {
      "epoch": 1.5281501340482575,
      "grad_norm": 5.500096797943115,
      "learning_rate": 4.64510419093841e-05,
      "loss": 0.2126,
      "step": 11400
    },
    {
      "epoch": 1.5415549597855227,
      "grad_norm": 2.3288769721984863,
      "learning_rate": 4.635026033462103e-05,
      "loss": 0.1911,
      "step": 11500
    },
    {
      "epoch": 1.5549597855227884,
      "grad_norm": 2.8645620346069336,
      "learning_rate": 4.6248180279021e-05,
      "loss": 0.188,
      "step": 11600
    },
    {
      "epoch": 1.5683646112600536,
      "grad_norm": 16.39829444885254,
      "learning_rate": 4.61448079508922e-05,
      "loss": 0.199,
      "step": 11700
    },
    {
      "epoch": 1.5817694369973192,
      "grad_norm": 11.449482917785645,
      "learning_rate": 4.604014963713629e-05,
      "loss": 0.1891,
      "step": 11800
    },
    {
      "epoch": 1.5951742627345844,
      "grad_norm": 7.48112154006958,
      "learning_rate": 4.593421170286605e-05,
      "loss": 0.2327,
      "step": 11900
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 8.772071838378906,
      "learning_rate": 4.582700059101824e-05,
      "loss": 0.2015,
      "step": 12000
    },
    {
      "epoch": 1.6219839142091153,
      "grad_norm": 0.8519721627235413,
      "learning_rate": 4.5719613848006667e-05,
      "loss": 0.1906,
      "step": 12100
    },
    {
      "epoch": 1.6353887399463807,
      "grad_norm": 4.5293965339660645,
      "learning_rate": 4.5609888586835084e-05,
      "loss": 0.2409,
      "step": 12200
    },
    {
      "epoch": 1.648793565683646,
      "grad_norm": 1.3455963134765625,
      "learning_rate": 4.5498909872779907e-05,
      "loss": 0.209,
      "step": 12300
    },
    {
      "epoch": 1.6621983914209115,
      "grad_norm": 0.46794214844703674,
      "learning_rate": 4.5386684455348236e-05,
      "loss": 0.189,
      "step": 12400
    },
    {
      "epoch": 1.675603217158177,
      "grad_norm": 3.624542713165283,
      "learning_rate": 4.527321915986919e-05,
      "loss": 0.1662,
      "step": 12500
    },
    {
      "epoch": 1.6890080428954424,
      "grad_norm": 0.5811871886253357,
      "learning_rate": 4.515852088707887e-05,
      "loss": 0.189,
      "step": 12600
    },
    {
      "epoch": 1.7024128686327078,
      "grad_norm": 0.44031959772109985,
      "learning_rate": 4.50425966127006e-05,
      "loss": 0.2245,
      "step": 12700
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 10.858154296875,
      "learning_rate": 4.492545338702073e-05,
      "loss": 0.2204,
      "step": 12800
    },
    {
      "epoch": 1.7292225201072386,
      "grad_norm": 5.174741744995117,
      "learning_rate": 4.480709833445981e-05,
      "loss": 0.1758,
      "step": 12900
    },
    {
      "epoch": 1.742627345844504,
      "grad_norm": 1.366578221321106,
      "learning_rate": 4.468753865313934e-05,
      "loss": 0.2075,
      "step": 13000
    },
    {
      "epoch": 1.7560321715817695,
      "grad_norm": 1.5176798105239868,
      "learning_rate": 4.456678161444395e-05,
      "loss": 0.2476,
      "step": 13100
    },
    {
      "epoch": 1.7694369973190347,
      "grad_norm": 0.4529476761817932,
      "learning_rate": 4.444483456257922e-05,
      "loss": 0.1974,
      "step": 13200
    },
    {
      "epoch": 1.7828418230563003,
      "grad_norm": 5.222200870513916,
      "learning_rate": 4.4321704914124954e-05,
      "loss": 0.1994,
      "step": 13300
    },
    {
      "epoch": 1.7962466487935655,
      "grad_norm": 5.752741813659668,
      "learning_rate": 4.419740015758417e-05,
      "loss": 0.1841,
      "step": 13400
    },
    {
      "epoch": 1.8096514745308312,
      "grad_norm": 7.42403507232666,
      "learning_rate": 4.4071927852927654e-05,
      "loss": 0.182,
      "step": 13500
    },
    {
      "epoch": 1.8230563002680964,
      "grad_norm": 6.6280131340026855,
      "learning_rate": 4.394529563113416e-05,
      "loss": 0.1946,
      "step": 13600
    },
    {
      "epoch": 1.836461126005362,
      "grad_norm": 8.199575424194336,
      "learning_rate": 4.381751119372636e-05,
      "loss": 0.2059,
      "step": 13700
    },
    {
      "epoch": 1.8498659517426272,
      "grad_norm": 3.616957664489746,
      "learning_rate": 4.368858231230234e-05,
      "loss": 0.2143,
      "step": 13800
    },
    {
      "epoch": 1.863270777479893,
      "grad_norm": 1.5532950162887573,
      "learning_rate": 4.355851682806308e-05,
      "loss": 0.1896,
      "step": 13900
    },
    {
      "epoch": 1.876675603217158,
      "grad_norm": 7.659707546234131,
      "learning_rate": 4.342732265133549e-05,
      "loss": 0.1976,
      "step": 14000
    },
    {
      "epoch": 1.8900804289544237,
      "grad_norm": 3.3222239017486572,
      "learning_rate": 4.329500776109134e-05,
      "loss": 0.1913,
      "step": 14100
    },
    {
      "epoch": 1.903485254691689,
      "grad_norm": 8.382903099060059,
      "learning_rate": 4.3162919961137784e-05,
      "loss": 0.1866,
      "step": 14200
    },
    {
      "epoch": 1.9168900804289544,
      "grad_norm": 3.1238162517547607,
      "learning_rate": 4.302839885805133e-05,
      "loss": 0.1944,
      "step": 14300
    },
    {
      "epoch": 1.9302949061662198,
      "grad_norm": 6.2129669189453125,
      "learning_rate": 4.289278130320873e-05,
      "loss": 0.2057,
      "step": 14400
    },
    {
      "epoch": 1.9436997319034852,
      "grad_norm": 2.377474546432495,
      "learning_rate": 4.275607554460289e-05,
      "loss": 0.2092,
      "step": 14500
    },
    {
      "epoch": 1.9571045576407506,
      "grad_norm": 5.2999091148376465,
      "learning_rate": 4.2618289896409156e-05,
      "loss": 0.2337,
      "step": 14600
    },
    {
      "epoch": 1.970509383378016,
      "grad_norm": 7.984280586242676,
      "learning_rate": 4.2479432738479617e-05,
      "loss": 0.2158,
      "step": 14700
    },
    {
      "epoch": 1.9839142091152815,
      "grad_norm": 0.8892210721969604,
      "learning_rate": 4.233951251583349e-05,
      "loss": 0.2216,
      "step": 14800
    },
    {
      "epoch": 1.997319034852547,
      "grad_norm": 5.152646541595459,
      "learning_rate": 4.219853773814348e-05,
      "loss": 0.2002,
      "step": 14900
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.928125,
      "eval_f1": 0.9294904982068887,
      "eval_loss": 0.22488124668598175,
      "eval_precision": 0.9332613737862903,
      "eval_recall": 0.9270331079186146,
      "eval_runtime": 0.7137,
      "eval_samples_per_second": 896.748,
      "eval_steps_per_second": 14.012,
      "step": 14920
    },
    {
      "epoch": 2.0107238605898123,
      "grad_norm": 4.526782035827637,
      "learning_rate": 4.205651697921826e-05,
      "loss": 0.2084,
      "step": 15000
    },
    {
      "epoch": 2.0241286863270775,
      "grad_norm": 7.995363235473633,
      "learning_rate": 4.191345887648105e-05,
      "loss": 0.2248,
      "step": 15100
    },
    {
      "epoch": 2.037533512064343,
      "grad_norm": 0.9238563179969788,
      "learning_rate": 4.1769372130444236e-05,
      "loss": 0.2071,
      "step": 15200
    },
    {
      "epoch": 2.0509383378016084,
      "grad_norm": 0.7496014833450317,
      "learning_rate": 4.162426550418031e-05,
      "loss": 0.2176,
      "step": 15300
    },
    {
      "epoch": 2.064343163538874,
      "grad_norm": 7.746445655822754,
      "learning_rate": 4.1478147822788825e-05,
      "loss": 0.2149,
      "step": 15400
    },
    {
      "epoch": 2.0777479892761392,
      "grad_norm": 0.8881396651268005,
      "learning_rate": 4.133102797285977e-05,
      "loss": 0.1871,
      "step": 15500
    },
    {
      "epoch": 2.091152815013405,
      "grad_norm": 9.683052062988281,
      "learning_rate": 4.1182914901933015e-05,
      "loss": 0.1921,
      "step": 15600
    },
    {
      "epoch": 2.10455764075067,
      "grad_norm": 5.422863006591797,
      "learning_rate": 4.10338176179542e-05,
      "loss": 0.1513,
      "step": 15700
    },
    {
      "epoch": 2.1179624664879357,
      "grad_norm": 4.175167083740234,
      "learning_rate": 4.0883745188726855e-05,
      "loss": 0.1892,
      "step": 15800
    },
    {
      "epoch": 2.131367292225201,
      "grad_norm": 2.7740628719329834,
      "learning_rate": 4.0732706741360925e-05,
      "loss": 0.1818,
      "step": 15900
    },
    {
      "epoch": 2.1447721179624666,
      "grad_norm": 4.571382522583008,
      "learning_rate": 4.0580711461717686e-05,
      "loss": 0.2052,
      "step": 16000
    },
    {
      "epoch": 2.158176943699732,
      "grad_norm": 6.555423736572266,
      "learning_rate": 4.042776859385107e-05,
      "loss": 0.2104,
      "step": 16100
    },
    {
      "epoch": 2.1715817694369974,
      "grad_norm": 3.3928439617156982,
      "learning_rate": 4.027543086482544e-05,
      "loss": 0.1718,
      "step": 16200
    },
    {
      "epoch": 2.1849865951742626,
      "grad_norm": 1.1077793836593628,
      "learning_rate": 4.012063002539605e-05,
      "loss": 0.2156,
      "step": 16300
    },
    {
      "epoch": 2.1983914209115283,
      "grad_norm": 5.644767761230469,
      "learning_rate": 3.996490957899125e-05,
      "loss": 0.1836,
      "step": 16400
    },
    {
      "epoch": 2.2117962466487935,
      "grad_norm": 4.349767684936523,
      "learning_rate": 3.9808278996222266e-05,
      "loss": 0.2085,
      "step": 16500
    },
    {
      "epoch": 2.225201072386059,
      "grad_norm": 1.1605349779129028,
      "learning_rate": 3.965074780305306e-05,
      "loss": 0.1843,
      "step": 16600
    },
    {
      "epoch": 2.2386058981233243,
      "grad_norm": 6.852755546569824,
      "learning_rate": 3.949232558022091e-05,
      "loss": 0.1556,
      "step": 16700
    },
    {
      "epoch": 2.25201072386059,
      "grad_norm": 12.160428047180176,
      "learning_rate": 3.933302196265382e-05,
      "loss": 0.1917,
      "step": 16800
    },
    {
      "epoch": 2.265415549597855,
      "grad_norm": 0.27911531925201416,
      "learning_rate": 3.917284663888443e-05,
      "loss": 0.2045,
      "step": 16900
    },
    {
      "epoch": 2.278820375335121,
      "grad_norm": 6.122848987579346,
      "learning_rate": 3.901180935046088e-05,
      "loss": 0.1655,
      "step": 17000
    },
    {
      "epoch": 2.292225201072386,
      "grad_norm": 3.027191638946533,
      "learning_rate": 3.884991989135427e-05,
      "loss": 0.2023,
      "step": 17100
    },
    {
      "epoch": 2.3056300268096512,
      "grad_norm": 11.99533748626709,
      "learning_rate": 3.868718810736307e-05,
      "loss": 0.2083,
      "step": 17200
    },
    {
      "epoch": 2.319034852546917,
      "grad_norm": 7.368117332458496,
      "learning_rate": 3.8523623895514295e-05,
      "loss": 0.1863,
      "step": 17300
    },
    {
      "epoch": 2.3324396782841825,
      "grad_norm": 1.161255955696106,
      "learning_rate": 3.835923720346154e-05,
      "loss": 0.1911,
      "step": 17400
    },
    {
      "epoch": 2.3458445040214477,
      "grad_norm": 1.3715683221817017,
      "learning_rate": 3.81940380288801e-05,
      "loss": 0.2097,
      "step": 17500
    },
    {
      "epoch": 2.359249329758713,
      "grad_norm": 6.4903035163879395,
      "learning_rate": 3.802803641885881e-05,
      "loss": 0.1914,
      "step": 17600
    },
    {
      "epoch": 2.3726541554959786,
      "grad_norm": 1.5879156589508057,
      "learning_rate": 3.786124246928905e-05,
      "loss": 0.1685,
      "step": 17700
    },
    {
      "epoch": 2.386058981233244,
      "grad_norm": 7.649287700653076,
      "learning_rate": 3.769366632425075e-05,
      "loss": 0.1845,
      "step": 17800
    },
    {
      "epoch": 2.3994638069705094,
      "grad_norm": 1.6943702697753906,
      "learning_rate": 3.752531817539543e-05,
      "loss": 0.1914,
      "step": 17900
    },
    {
      "epoch": 2.4128686327077746,
      "grad_norm": 3.831568479537964,
      "learning_rate": 3.7356208261326356e-05,
      "loss": 0.2328,
      "step": 18000
    },
    {
      "epoch": 2.4262734584450403,
      "grad_norm": 7.832396984100342,
      "learning_rate": 3.718634686697584e-05,
      "loss": 0.1852,
      "step": 18100
    },
    {
      "epoch": 2.4396782841823055,
      "grad_norm": 3.4600830078125,
      "learning_rate": 3.701745398307891e-05,
      "loss": 0.1887,
      "step": 18200
    },
    {
      "epoch": 2.453083109919571,
      "grad_norm": 6.361461162567139,
      "learning_rate": 3.6846127921381576e-05,
      "loss": 0.2068,
      "step": 18300
    },
    {
      "epoch": 2.4664879356568363,
      "grad_norm": 2.031404972076416,
      "learning_rate": 3.6674081401485746e-05,
      "loss": 0.1967,
      "step": 18400
    },
    {
      "epoch": 2.479892761394102,
      "grad_norm": 1.9173732995986938,
      "learning_rate": 3.650132488692234e-05,
      "loss": 0.1836,
      "step": 18500
    },
    {
      "epoch": 2.493297587131367,
      "grad_norm": 0.5386676788330078,
      "learning_rate": 3.632786888440276e-05,
      "loss": 0.2026,
      "step": 18600
    },
    {
      "epoch": 2.506702412868633,
      "grad_norm": 0.7565786838531494,
      "learning_rate": 3.6153723943179876e-05,
      "loss": 0.1911,
      "step": 18700
    },
    {
      "epoch": 2.520107238605898,
      "grad_norm": 5.220411777496338,
      "learning_rate": 3.5978900654406476e-05,
      "loss": 0.1963,
      "step": 18800
    },
    {
      "epoch": 2.5335120643431637,
      "grad_norm": 3.903013229370117,
      "learning_rate": 3.58034096504911e-05,
      "loss": 0.1849,
      "step": 18900
    },
    {
      "epoch": 2.546916890080429,
      "grad_norm": 5.73792839050293,
      "learning_rate": 3.562902630212707e-05,
      "loss": 0.1892,
      "step": 19000
    },
    {
      "epoch": 2.5603217158176945,
      "grad_norm": 8.007728576660156,
      "learning_rate": 3.545223833707334e-05,
      "loss": 0.1711,
      "step": 19100
    },
    {
      "epoch": 2.5737265415549597,
      "grad_norm": 7.1129655838012695,
      "learning_rate": 3.527481468744382e-05,
      "loss": 0.1926,
      "step": 19200
    },
    {
      "epoch": 2.5871313672922254,
      "grad_norm": 7.94758415222168,
      "learning_rate": 3.509676614379587e-05,
      "loss": 0.1811,
      "step": 19300
    },
    {
      "epoch": 2.6005361930294906,
      "grad_norm": 6.121910095214844,
      "learning_rate": 3.491810353469169e-05,
      "loss": 0.2097,
      "step": 19400
    },
    {
      "epoch": 2.6139410187667558,
      "grad_norm": 4.675015926361084,
      "learning_rate": 3.4738837726039733e-05,
      "loss": 0.1984,
      "step": 19500
    },
    {
      "epoch": 2.6273458445040214,
      "grad_norm": 5.3506855964660645,
      "learning_rate": 3.455897962043387e-05,
      "loss": 0.1853,
      "step": 19600
    },
    {
      "epoch": 2.640750670241287,
      "grad_norm": 2.940115451812744,
      "learning_rate": 3.437854015649028e-05,
      "loss": 0.195,
      "step": 19700
    },
    {
      "epoch": 2.6541554959785523,
      "grad_norm": 7.8397393226623535,
      "learning_rate": 3.419753030818223e-05,
      "loss": 0.216,
      "step": 19800
    },
    {
      "epoch": 2.6675603217158175,
      "grad_norm": 0.8881692886352539,
      "learning_rate": 3.401596108417267e-05,
      "loss": 0.2108,
      "step": 19900
    },
    {
      "epoch": 2.680965147453083,
      "grad_norm": 0.7878021001815796,
      "learning_rate": 3.383384352714462e-05,
      "loss": 0.1394,
      "step": 20000
    },
    {
      "epoch": 2.6943699731903488,
      "grad_norm": 3.3990859985351562,
      "learning_rate": 3.365118871312967e-05,
      "loss": 0.1855,
      "step": 20100
    },
    {
      "epoch": 2.707774798927614,
      "grad_norm": 5.109147071838379,
      "learning_rate": 3.346800775083434e-05,
      "loss": 0.1678,
      "step": 20200
    },
    {
      "epoch": 2.721179624664879,
      "grad_norm": 1.8512154817581177,
      "learning_rate": 3.328431178096443e-05,
      "loss": 0.1834,
      "step": 20300
    },
    {
      "epoch": 2.734584450402145,
      "grad_norm": 1.6548292636871338,
      "learning_rate": 3.3100111975547485e-05,
      "loss": 0.1706,
      "step": 20400
    },
    {
      "epoch": 2.7479892761394105,
      "grad_norm": 8.468707084655762,
      "learning_rate": 3.2915419537253346e-05,
      "loss": 0.1811,
      "step": 20500
    },
    {
      "epoch": 2.7613941018766757,
      "grad_norm": 2.094891309738159,
      "learning_rate": 3.273024569871281e-05,
      "loss": 0.1738,
      "step": 20600
    },
    {
      "epoch": 2.774798927613941,
      "grad_norm": 7.779872894287109,
      "learning_rate": 3.2544601721834515e-05,
      "loss": 0.2435,
      "step": 20700
    },
    {
      "epoch": 2.7882037533512065,
      "grad_norm": 9.022781372070312,
      "learning_rate": 3.2358498897119936e-05,
      "loss": 0.1997,
      "step": 20800
    },
    {
      "epoch": 2.8016085790884717,
      "grad_norm": 5.525753021240234,
      "learning_rate": 3.2171948542976824e-05,
      "loss": 0.2027,
      "step": 20900
    },
    {
      "epoch": 2.8150134048257374,
      "grad_norm": 9.281534194946289,
      "learning_rate": 3.198496200503077e-05,
      "loss": 0.2,
      "step": 21000
    },
    {
      "epoch": 2.8284182305630026,
      "grad_norm": 5.454533576965332,
      "learning_rate": 3.1797550655435184e-05,
      "loss": 0.1889,
      "step": 21100
    },
    {
      "epoch": 2.841823056300268,
      "grad_norm": 7.939429759979248,
      "learning_rate": 3.160972589217973e-05,
      "loss": 0.2092,
      "step": 21200
    },
    {
      "epoch": 2.8552278820375334,
      "grad_norm": 1.698093056678772,
      "learning_rate": 3.1421499138397026e-05,
      "loss": 0.161,
      "step": 21300
    },
    {
      "epoch": 2.868632707774799,
      "grad_norm": 4.96559476852417,
      "learning_rate": 3.1232881841668015e-05,
      "loss": 0.196,
      "step": 21400
    },
    {
      "epoch": 2.8820375335120643,
      "grad_norm": 1.7573250532150269,
      "learning_rate": 3.1043885473325645e-05,
      "loss": 0.171,
      "step": 21500
    },
    {
      "epoch": 2.89544235924933,
      "grad_norm": 4.256712913513184,
      "learning_rate": 3.08545215277573e-05,
      "loss": 0.1695,
      "step": 21600
    },
    {
      "epoch": 2.908847184986595,
      "grad_norm": 3.733351469039917,
      "learning_rate": 3.066480152170565e-05,
      "loss": 0.1794,
      "step": 21700
    },
    {
      "epoch": 2.9222520107238603,
      "grad_norm": 0.19795526564121246,
      "learning_rate": 3.047473699356828e-05,
      "loss": 0.2029,
      "step": 21800
    },
    {
      "epoch": 2.935656836461126,
      "grad_norm": 2.7154204845428467,
      "learning_rate": 3.0284339502695935e-05,
      "loss": 0.2248,
      "step": 21900
    },
    {
      "epoch": 2.9490616621983916,
      "grad_norm": 5.205166816711426,
      "learning_rate": 3.0093620628689484e-05,
      "loss": 0.1731,
      "step": 22000
    },
    {
      "epoch": 2.962466487935657,
      "grad_norm": 3.9595115184783936,
      "learning_rate": 2.9902591970695705e-05,
      "loss": 0.1518,
      "step": 22100
    },
    {
      "epoch": 2.975871313672922,
      "grad_norm": 1.966954231262207,
      "learning_rate": 2.97112651467018e-05,
      "loss": 0.1865,
      "step": 22200
    },
    {
      "epoch": 2.9892761394101877,
      "grad_norm": 5.142547607421875,
      "learning_rate": 2.9519651792828877e-05,
      "loss": 0.2218,
      "step": 22300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9328125,
      "eval_f1": 0.9341508698187163,
      "eval_loss": 0.2184281051158905,
      "eval_precision": 0.9346153505132281,
      "eval_recall": 0.93380556092021,
      "eval_runtime": 0.7115,
      "eval_samples_per_second": 899.534,
      "eval_steps_per_second": 14.055,
      "step": 22380
    }
  ],
  "logging_steps": 100,
  "max_steps": 44760,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.110990210555904e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
